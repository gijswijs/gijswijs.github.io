<!DOCTYPE html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=description content="Gijs van Dam is a freelance consultant and crypto researcher with over 20 years of international experience, who tries to make the web a better place."><link rel="shortcut icon" href=/favicon.ico><link rel=apple-touch-icon sizes=57x57 href=/apple-icon-57x57.png><link rel=apple-touch-icon sizes=60x60 href=/apple-icon-60x60.png><link rel=apple-touch-icon sizes=72x72 href=/apple-icon-72x72.png><link rel=apple-touch-icon sizes=76x76 href=/apple-icon-76x76.png><link rel=apple-touch-icon sizes=114x114 href=/apple-icon-114x114.png><link rel=apple-touch-icon sizes=120x120 href=/apple-icon-120x120.png><link rel=apple-touch-icon sizes=144x144 href=/apple-icon-144x144.png><link rel=apple-touch-icon sizes=152x152 href=/apple-icon-152x152.png><link rel=apple-touch-icon sizes=180x180 href=/apple-icon-180x180.png><link rel=icon type=image/png sizes=192x192 href=/android-icon-192x192.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=96x96 href=/favicon-96x96.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><meta name=msapplication-TileColor content=#ffffff><meta name=msapplication-TileImage content=/ms-icon-144x144.png><meta name=theme-color content=#ffffff><title>Gijs van Dam</title><link href=/styles/main.css rel=stylesheet><link rel=alternate type=application/rss+xml title="Gijs van Dam" href=/rss.xml><link rel=webmention href=https://webmention.io/www.gijsvandam.nl/webmention><link rel=pingback href=https://webmention.io/www.gijsvandam.nl/xmlrpc><link rel=authorization_endpoint href=https://janos-githubproxy.azurewebsites.net/api/authorize/gijswijs/gijswijs.github.io><link rel=token_endpoint href=https://janos-githubproxy.azurewebsites.net/api/token/gijswijs/gijswijs.github.io><link rel=microsub href=https://aperture.p3k.io/microsub/636><link rel=micropub href=https://janos-githubproxy.azurewebsites.net/api/micropub/gijswijs/gijswijs.github.io></head><body class=stream><header>Gijs van Dam<nav><ul><li><a href=/ title=Home>Home</a></li><li><a href=/research title=Research>Research</a></li><li><a href=/open-source title="Open Source">Open Source</a></li><li><a href=/ventures title=Ventures>Ventures</a></li><li><a href=/resume title=Resume>Resume</a></li><li><a href=/about title=About>About</a></li><li><a href=/now title=Now>Now</a></li><li><a href=/contact title=Contact>Contact</a></li></ul></nav></header><main><ul class=h-feed><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><div class=e-content><p>Note with picture</p></div></div></div><div class=metadata><a href=/note/2022/02/15-44835 class=u-url><time class=dt-published datetime=2022-02-15T12:27:15Z>2022-02-15 12:27:15 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><div class=e-content><p>Test: Note wit a picture</p></div></div></div><div class=metadata><a href=/note/2022/02/15-35473 class=u-url><time class=dt-published datetime=2022-02-15T09:51:13Z>2022-02-15 09:51:13 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><div class=e-content><p>TEST: Let&#39;s see if we can wait for this tweet to come online.</p></div></div></div><div class=metadata><a href=/note/2022/02/15-34237 class=u-url><time class=dt-published datetime=2022-02-15T09:30:37Z>2022-02-15 09:30:37 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><div class=e-content><p>TEST: Let&#39;s see if we can wait for this tweet to come online.</p></div></div></div><div class=metadata><a href=/note/2022/02/15-33268 class=u-url><time class=dt-published datetime=2022-02-15T09:14:28Z>2022-02-15 09:14:28 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><div class=e-content><p>Test: Note wit a picture</p></div></div></div><div class=metadata><a href=/note/2022/02/15-32499 class=u-url><time class=dt-published datetime=2022-02-15T09:01:39Z>2022-02-15 09:01:39 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><div class=e-content><p>Test: Does syndication now work? <a href=https://brid.gy/publish/twitter></a></p></div></div></div><div class=metadata><i class=icon-reply>&nbsp;</i> 1 reply</div><div class=metadata><a href=/note/2022/02/15-32251 class=u-url><time class=dt-published datetime=2022-02-15T08:57:31Z>2022-02-15 08:57:31 +00:00</time> </a><a href=https://twitter.com/gijswijs/status/1493510063658569734 class="u-syndication icon-twitter">twitter</a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><div class=e-content><p>TEST: Let&#39;s see if we can wait for this tweet to come online.</p></div></div></div><div class=metadata><a href=/note/2022/02/15-30403 class=u-url><time class=dt-published datetime=2022-02-15T08:26:43Z>2022-02-15 08:26:43 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><div class=e-content><p>TEST: Let&#39;s see if we can wait for this tweet to come online.</p></div></div></div><div class=metadata><a href=/note/2022/02/15-29847 class=u-url><time class=dt-published datetime=2022-02-15T08:17:27Z>2022-02-15 08:17:27 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><div class=e-content><p>Let&#39;s see if syndication no works.</p></div></div></div><div class=metadata><a href=/note/2022/02/15-27171 class=u-url><time class=dt-published datetime=2022-02-15T07:32:51Z>2022-02-15 07:32:51 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><h1 class=p-name>Image conversion, resizing and compression with WebAssembly</h1><div class=e-content><p>Image conversion and resizing for the web can be quite fiddly. Take responsive websites for instance. You want to show a smaller version of your image on smaller devices: You don&#39;t need to download a 1080px wide image to show on a 360px wide device, especially since that device is likely constrained in the amount of bandwidth it has. Then again when your website is shown on an ultra HD screen with 3840x2160 resolution 1080 is maybe even too small.</p><p>Apart from multiple sizes, you also want to offer multiple formats. Modern browsers support new(er) image formats like webp and avif offer better compression for comparable image quality. Using these formats you can decrease the total download size of your page, while improving the overall experience for the user. But you just can&#39;t assume (yet) that all browsers support those newer formats, so you have to provide older formats as a fallback option. All in all the amount of different files you have to offer for just a single image on a web page starts to become quite large and the whole thing becomes, like I said, fiddly.</p><p>Now look at the gif below.</p><p><picture><img src=/images/copy-paste-image.gif alt="animated gif of copy-pasting images with Janos" title="Copy-pasting an image in Janos" loading=lazy decoding=async width=888 height=662><figcaption>Copy-pasting an image in Janos</figcaption></picture></p><p>What is happening here? The gif shows the process of screen clipping an image and then pasting it inside the Janos editor. Upon pasting the image, the image is &quot;uploaded&quot;, and that starts a process of resizing and conversion. I use scare quotes around <em>uploaded</em>, because there isn&#39;t anything uploaded yet. Janos uses a small git client under the hood that stores the file in memory as a git blob. Only after committing to GitHub files are really uploaded to the GitHub servers. The pasted image is resized to three different sizes and three different formats (avif, webp and jpg), so in total 9 versions of the image are created. The original image is also stored in all its unresized greatness, making the total amount of files a nice 10. If the original image is copy-pasted like in the example above, it is stored as a png file. If the image is &quot;uploaded&quot; as a file it&#39;s kept as-is.</p><p>This workflow takes the fiddle out of fiddly and leaves us with a nice process of putting images inside a post without hassle. But the attentive reader might ask:</p><blockquote><p>How does this work? -- Attentive reader</p></blockquote><p>Since an actual upload hasn&#39;t happened yet, this whole process has to take place inside the browser and it uses WebAssembly to make it happen.</p><h2 id=conversion-and-resizing-with-webassembly>Conversion and resizing with WebAssembly</h2><p>GoogleChromeLabs has made the <a href=https://github.com/GoogleChromeLabs/squoosh>Squoosh app</a>, an amazing web app that offers image compression in all the formats you want. It also offers a Squoosh cli for compressing multiple files at once. I forked Squoosh and made a simple (and hacky) version of the Squoosh cli that runs in the browser. It is like a <em>headless</em> version of the Squoosh app, if you will. For each format Squoosh supports, it uses a codec (did you know codec is a portmanteau of coder-decoder?) developed in either Rust or C++ and compiled to WebAssembly. So this enables the browser to do some pretty heavy lifting with regards to resizing and converting our image. If I run it on my laptop I can hear the fans spin up to cope with the demands of the cpu.</p><h2 id=from-markdown-to-html>From Markdown to html</h2><p>After pasting the image, the Markdown syntax for inserting an image is pasted in the document with a reference to the original file. But that is obviously not the file we want to show in the resulting HTML. In our HTML we want an picture element that contains all our files in all formats and sizes. It should look like this:</p><pre><code class=language-html>&lt;picture
  &gt;&lt;source
    srcset=&quot;
      /images/ever-given_s.avif 461w,
      /images/ever-given_m.avif 692w,
      /images/ever-given_l.avif 922w
    &quot;
    type=&quot;image/avif&quot; /&gt;
  &lt;source
    srcset=&quot;
      /images/ever-given_s.webp 461w,
      /images/ever-given_m.webp 692w,
      /images/ever-given_l.webp 922w
    &quot;
    type=&quot;image/webp&quot; /&gt;
  &lt;img
    srcset=&quot;
      /images/ever-given_s.jpg 461w,
      /images/ever-given_m.jpg 692w,
      /images/ever-given_l.jpg 922w
    &quot;
    src=&quot;/images/ever-given_s.jpg&quot;
    alt=&quot;Container ship Ever Given&quot;
    title=&quot;Container ship Ever Given stuck in the Suez Canal&quot;
    loading=&quot;lazy&quot;
    decoding=&quot;async&quot;
    width=&quot;922&quot;
    height=&quot;480&quot;
/&gt;&lt;/picture&gt;
&lt;figcaption&gt;/images/todo-tree.jpg&lt;/figcaption&gt;</code></pre><p>The above snippet is derived from this <a href=https://www.stefanjudis.com/snippets/a-picture-element-to-load-correctly-resized-webp-images-in-html/ >snippet</a> with some minor adjustments. It uses <code>srcSet</code> to offer the different sizes of the image. It uses different <code>srcSet</code> to offer the different formats, and it uses <code>src</code> to offer the smallest version to browsers that don&#39;t support any of it. Since <a href=https://www.smashingmagazine.com/2020/03/setting-height-width-images-important-again/ >width &amp; height are important</a> for rendering pages fast without layout shifts, we add the width and height from the <em>largest</em> version of the image. This did result in some problems that took quite some time to get figured out:</p><p>Apparently the use of <code>width</code> and <code>height</code> nullifies any use of the <code>sizes</code> attribute in combination with the <code>srcSet</code>. The <code>sizes</code> attribute is meant for defining a set of media conditions (e.g. screen widths) and indicates what image size would be best to choose. The browser uses that info in combination with other information (like device-pixel-ratio) to determine which image file it will download. But because we want to use <code>width</code> and <code>height</code> this means that the <code>sizes</code> attribute is unavailable to us. So we are forced to use good ol&#39; css to indicate the different image sizes under different media conditions.</p><pre><code class=language-css>.article img {
  max-width: 100%;
  height: auto;
}
figcaption {
  text-align: center;
  margin-top: -1.5rem;
  font-style: italic;
}
@media (min-width: 40rem) {
  .article img {
    max-width: calc(100% - 6rem);
    height: auto;
    margin: 0 3rem;
  }
}
@media (min-width: 80rem) {
  .article img {
    max-width: calc(100% - 12rem);
    height: auto;
    margin: 0 6rem;
  }
}</code></pre><h2 id=metalsmith-plugin-for-the-picture-element>Metalsmith plugin for the picture element</h2><p>The final ingredient in this mix is a metalsmith plugin that creates the HTML picture element, based on the image referenced in the Markdown. It detects the image, figures out what kind of resized files are available and then converts the Markdown to a picture element. So in the end the picture will look like this:</p><p><picture><source srcset="/images/ever-given_s.avif 540w,/images/ever-given_m.avif 810w,/images/ever-given_l.avif 1080w" type=image/avif><source srcset="/images/ever-given_s.webp 540w,/images/ever-given_m.webp 810w,/images/ever-given_l.webp 1080w" type=image/webp><img srcset="/images/ever-given_s.jpg 540w,/images/ever-given_m.jpg 810w,/images/ever-given_l.jpg 1080w" src=/images/ever-given_s.jpg alt="Container ship Ever Given" title="Container ship Ever Given stuck in the Suez Canal" loading=lazy decoding=async width=1080 height=609><figcaption>Container ship Ever Given stuck in the Suez Canal</figcaption></picture></p><h2 id=releasing-everything-as-separate-modules>Releasing everything as separate modules</h2><p>Currently everything is integrated inside the Janos code base. But I plan on releasing both the <em>headless</em> Squoosh library and the Metalsmith plugin as separate npm modules. When that is done and dusted I will do write-up on how to use and configure said modules to suit your needs.</p></div></div></div><div class=metadata><i class=icon-like>&nbsp;</i> 3 likes <i class=icon-reply>&nbsp;</i> 2 replies</div><div class=metadata><a href=/post/image-conversion-resizing-and-compression-with-webassembly class=u-url><time class=dt-published datetime=2021-03-31T00:00:00Z>2021-03-31 00:00:00 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><h1 class=p-name>Measuring your writing progress with a git word count</h1><div class=e-content><p>Writing a scientific paper is hard. Doing your PhD is hard. Writing your thesis is hard. And to make me feel even more miserable I decided to measure my progress by counting the net change in words I achieve throughout each day. I am by no means a productivity guru and I don&#39;t know whether word count is a useful indicator for measuring the progress of a paper. That being said, it is a reality check to see how fast my work is progressing. So without further ado here&#39;s the Powershell command that outputs the wordcount for the last 25 days based on git commits.</p><pre><code class=language-powershell>for($i = 0; $i -lt 25; $i++){$j = $i + 1; Write-Host (get-date (get-date).addDays(-$i) -UFormat &quot;%Y%m%d&quot;) ((git diff --word-diff=porcelain &quot;@{$j days ago}&quot; &quot;@{$i days ago}&quot;   -- &quot;***.md&quot;| Select-String -Pattern &quot;^\+.*&quot; | Measure-Object -word | select -ExpandProperty Words) - (git diff --word-diff=porcelain &quot;@{$j days ago}&quot; &quot;@{$i days ago}&quot;  -- &quot;***.md&quot;| Select-String -Pattern &quot;^-.*&quot; | Measure-Object -word | select -ExpandProperty Words)) }</code></pre><h2 id=what-does-it-do>What does it do?</h2><p>At the core of this script is the following git command:</p><pre><code>git diff --word-diff=porcelain &quot;@{$j days ago}&quot; &quot;@{$i days ago}&quot;   -- &quot;***.md&quot;</code></pre><p>This command uses <code>git diff</code> (duh!) with the <code>--word-diff</code> option which marks the actual word being changed instead of the entire line that contains it. The latter is the default behavior of <code>git diff</code> and is not what we want when performing a word count. <code>porcelain</code> denotes the special line-based format for <code>word-diff</code> meant for script consumption, which is what we will do next. <code>-- &quot;***.md&quot;</code> only considers markdown files which are the files that contain all the content of my paper in <a href=https://github.com/neumannjs/boilerplate-paper>Boilerplate Paper</a>. It is important to note that if you don&#39;t commit regularly (at least daily) this word count doesn&#39;t come up with accurate data.</p><p>If you run only this command, you would get something like this.</p><pre><code>~
diff --git a/e-diff-paper/paper/03_method.md b/e-diff-paper/paper/03_method.md
index a3b4dfe..c4a565c 100644
--- a/e-diff-paper/paper/03_method.md
+++ b/e-diff-paper/paper/03_method.md
@@ -1,8 +1,8 @@
 # Method
~

~
 Our goal is to obtain differential privacy for the balance of a Lightning Network payment channel. This goal differs from the original setting of differential privacy. Originally differential privacy
-was
  meant to ensure that adding or deleting a record
-from
+in
  a database did not change the answer to statistical differential private queries significantly. To achieve that, noise is added to the query answer. By observing this noisy answer 
-a passive
+an
  observer is unable to discern if a specific record is in the database or not, regardless of the information this observer possesses about the other records in the database. This adding of noise is done through a probabilistic algorithm applied to the data set contained in the database.
~

~
 Our case is different in a consequential way. A passive observer can use a BDA again and again to get a reading on the balance. The information that this observer obtains is comparable to a stream of data. To cater to our situation we expand the basic definition of (approximate) differential privacy to 
-streams
+streams,
  similarly to [@Chan2011].</code></pre><p>Those lines starting with <code>-</code> or <code>+</code> are the ones we are interested in, because those are the words that have been deleted and added. We pipe the results of that command into <code>Select-String</code> which is kind of like grep for Powershell.</p><pre><code>Select-String -Pattern &quot;^\+(?!\+\+\s).*&quot;</code></pre><p>The regex pattern matches with all lines starting with <code>+</code> except if it is followed by <code>++</code> (we use the negative lookahead to check for that) because the three plus-signs are use to indicate file names that have additions, not the addition itself. If you run the above two commands piped together you would get a result like this:</p><pre><code>+#
+## Just-In-Time Routing
+Just-in-time routing or JIT routing [@Pickhardt2019] was proposed as a solution to mitigate routing failures due to insufficient funds. LN uses source based routing, where the send 
er of the payment has to guess the route over which to send a payment. Since a node is only aware of the balances of channels that it is part of, a sender node can only guess if a r
oute with other channels has enough liquidity to process the payment. This can lead to relatively large amounts of failed payments due to insufficient funds somewhere along the rout 
e.
+JIT Routing tries to make the routing process more like best effort routing known in IP-forwarding. The concept depends on nodes quickly rebalancing their channels upon receiving a
 routing request (HTLC) for which they have insufficient funds. Because a node along the route has more knowledge of its local neighborhood than the sender node, it can use that kno
wledge to perform a small transaction within its local neighborhood of channels to rebalance funds in such a way that original routing request can proceed. Given that the rebalancin 
g succeeds within the timeframe of the routing request, the requests now succeeds where it would have failed without JIT routing.
+in
+an
+streams,</code></pre><p>Although there is some Markdown markup that shouldn&#39;t be counted as words (like <code>#</code> and <code>##</code>) this is good enough for my purposes. So we pipe the results into our next two commands.</p><pre><code>Measure-Object -word | select -ExpandProperty Words</code></pre><p>These are plain and simple, the first command performs the actual word count, but since Powershell always returns an object, we need the latter command to enumerate the values of the object and select the value. Everything piped together returns just a number.</p><pre><code>248</code></pre><p>Now we do the same thing for the deleted words. We run the same commands but now with a different regex expression: <code>Select-String -Pattern &quot;^\-(?!\-\-\s).*&quot;</code></p><p>We substract the deleted words from the added words and we have our nett change in words for the day. All that is left to do is to wrap everything in a loop that goes back as much days as you want (25 in the above script) and outputs the date with the word count for that date.</p><p>So this is my progress for the past few days of a particular paper I am writing:</p><pre><code>20210226 237
20210225 0
20210224 0
20210223 0
20210222 0
20210221 0
20210220 0
20210219 0
20210218 591
20210217 190
20210216 332
20210215 0
20210214 0
20210213 0
20210212 0
20210211 925
20210210 0
20210209 382</code></pre><p>I guess I was just busy with other things...</p></div></div></div><div class=metadata><a href=/post/measuring-your-writing-progress-with-a-git-word-count class=u-url><time class=dt-published datetime=2021-02-26T00:00:00Z>2021-02-26 00:00:00 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><h1 class=p-name>Pandoc-filter for highlighting to-dos in LaTeX output</h1><div class=e-content><p>While writing my papers I try not to get bogged down too much. So if a paragraph doens&#39;t flow right I just type <code>TODO: rewrite</code> on the line below it, and continue writing. When I think of something that I shouldn&#39;t forget, like an extra analysis to run I just write it down as a todo in the running text of my paper. I also write thoughts on my paper as a todo. Ideas on structure, whether I should maybe rearrange paragraphs or approach a subject differently, it all ends up as a todo in the running text.</p><p>When running the VSCode task for converting my paper to PDF (using Pandoc) it puts all the todos into the running text. That&#39;s fine by me, it helps as an extra reminder that stuff still needs to happen. But I wanted the todos to be visually different from the running text, so that it stands apart and doesn&#39;t confuse people who are reading my draft. That is where my Pandoc filter comes into play.</p><p>While working inside VSCode I keep track off all todo&#39;s with the <a href="https://marketplace.visualstudio.com/items?itemName=Gruntfuggly.todo-tree">Todo Tree</a> extension. This extension searches your workspace for comment tags like TODO and FIXME, and displays them in a tree view in the explorer pane.</p><p><picture><source srcset="/images/todo-tree_s.avif 461w,/images/todo-tree_m.avif 692w,/images/todo-tree_l.avif 922w" type=image/avif><source srcset="/images/todo-tree_s.webp 461w,/images/todo-tree_m.webp 692w,/images/todo-tree_l.webp 922w" type=image/webp><img srcset="/images/todo-tree_s.jpg 461w,/images/todo-tree_m.jpg 692w,/images/todo-tree_l.jpg 922w" src=/images/todo-tree_s.jpg alt="Todo Tree in VSCode" title=/images/todo-tree.jpg loading=lazy decoding=async width=922 height=480><figcaption>/images/todo-tree.jpg</figcaption></picture></p><p>But to keep track of the todo&#39;s when the paper is converted to PDF I created a Pandoc filter that highlights all comments in LaTeX output formats. It is really simple:</p><pre><code class=language-lua>if FORMAT:match &#39;latex&#39; then
    function Para(el)
        if pandoc.utils.equals(pandoc.Str &#39;TODO:&#39;, el.content[1]) then 
            table.insert(el.content, 1, pandoc.RawInline(&#39;latex&#39;, &#39;\\hl{&#39;))
            table.insert(el.content, pandoc.RawInline(&#39;latex&#39;, &#39;}&#39;))
        end
        return el
    end
end</code></pre><p>The only prerequisite is that you put the <code>soul</code> package in the preamble of your LaTeX, because that is the package used for the highlighting. So somewhere in your preamble you should put this:</p><pre><code class=language-latex>\usepackage{soul}</code></pre><p>Now, if you output the paper, the todos are highlighted.</p><p><picture><source srcset="/images/todo-in-pdf_s.avif 540w,/images/todo-in-pdf_m.avif 810w,/images/todo-in-pdf_l.avif 1080w" type=image/avif><source srcset="/images/todo-in-pdf_s.webp 540w,/images/todo-in-pdf_m.webp 810w,/images/todo-in-pdf_l.webp 1080w" type=image/webp><img srcset="/images/todo-in-pdf_s.jpg 540w,/images/todo-in-pdf_m.jpg 810w,/images/todo-in-pdf_l.jpg 1080w" src=/images/todo-in-pdf_s.jpg alt="Todo in LaTeX PDF output" title="Todo in LaTeX PDF output" loading=lazy decoding=async width=1080 height=270><figcaption>Todo in LaTeX PDF output</figcaption></picture></p></div></div></div><div class=metadata><a href=/post/pandoc-filter-for-highlighting-to-dos-in-latex-output class=u-url><time class=dt-published datetime=2021-02-23T00:00:00Z>2021-02-23 00:00:00 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><h1 class=p-name>Super easy tip for slide animation with Pandoc and reveal.js</h1><div class=e-content><p>I found this super easy alternative way to animate your slides with reveal.js that works out of the box with Markdown and Pandoc. Here is how to do it.</p><p>Last week I had to give a progress presentation about the current state of my PhD, and I can whip those up in no time. I use <a href=https://github.com/neumannjs/boilerplate-paper>Boilerplate Paper</a> not only for writing my papers, but also for presentations like this.</p><p>I write the presentation in Markdown and then convert it to <a href=https://revealjs.com>reveal.js</a>. But sometimes you want something else than the default sliding transition that reveal.js provides.</p><p><picture><img src=/images/default-sliding.gif alt="Default sliding transition in reveal.js" title="Default sliding transition in reveal.js" loading=lazy decoding=async width=1000 height=704><figcaption>Default sliding transition in reveal.js</figcaption></picture></p><p>Reveal.js got you covered with <a href=https://revealjs.com/auto-animate/ >auto-animate</a>. It&#39;s a feature that automatically finds matching elements between two slides and animates between them. It&#39;s nothing too fancy and for me it perfectly fits the job at hand. All you need to do is add <code>data-auto-animate</code> to two adjacent slide <code>&lt;section&gt;</code> elements.</p><p>And the beautiful thing is, it works out of the box with Pandoc slides using heading attributes. In Pandoc headings can be assigned attributes at the end of the heading line.</p><pre><code>{#identifier .class key=value}</code></pre><p>In this case we are going to use the key/value attribute to add <code>data-auto-animate</code> to the reveal.js section. Just add <code>{data-auto-animate=}</code> (it needs only the key and no value, but it requires the <code>=</code>) to the end of the slide title, like so:</p><pre><code>## Slide 1 {data-auto-animate=}

Slide 1 content

## Slide 2 {data-auto-animate=}

Slide 2 content</code></pre><p>And that&#39;s it! Once you convert your Markdown into reveal.js the slides are now animated using auto-animate.</p><p><picture><img src=/images/auto-animate.gif alt="Auto-animate transition in reveal.js" title="Auto-animate transition in reveal.js" loading=lazy decoding=async width=1000 height=704><figcaption>Auto-animate transition in reveal.js</figcaption></picture></p></div></div></div><div class=metadata><a href=/post/super-easy-tip-for-slide-animation-with-pandoc-and-reveal.js class=u-url><time class=dt-published datetime=2021-02-15T00:00:00Z>2021-02-15 00:00:00 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><h1 class=p-name>Running c-lightning in Simverse with plugins</h1><div class=e-content><p>The goal is to run c-lightning with plugins in a local testing cluster. For my cluster I use <a href=https://github.com/darwin/simverse>Simverse</a>. Simverse allows for additional command line arguments to be passed to <code>lightningd</code>, so it should be possible to run <code>lightningd</code> with the <code>plugin</code> argument.</p><p>Let&#39;s first clone our plugin. We will be using one of the plugins that are available through Lightningd on Github.</p><pre><code>cd ~\simverse\_repos
git clone https://github.com/lightningd/plugins.git --depth 1</code></pre><p>We put the plugin in the <code>_repos</code> folder, because it is assumed that the plugin is there when the cluster is being build. (Also: throughout this article we assume your simverse folder is inside your home folder. If that is not the case, adjust it accordingly)</p><p>Since all nodes in Simverse run inside Docker containers, that plugin-file should be made available inside the Docker context folder. The <code>_repos</code> folder is not part of that context (each container gets its own context) so we have to copy the file from the <code>_repos</code> folder to the Docker context folder. Luckily Simverse works with the concept of recipes. A recipe describes how your cluster should look like. A recipe is a bash script that uses a library called cookbook that can be used to build your cluster step-by-step. Since it is &quot;just&quot; a bash script, you can do anything bash can do to tweak your cluster.</p><p>We will create a recipe that creates a cluster with three c-lightning nodes, running on a bitcoind back-end.</p><h2 id=simverse-recipe>Simverse Recipe</h2><pre><code class=language-bash>#!/usr/bin/env bash

. cookbook/cookbook.sh

prelude

add bitcoind

LIGHTNINGD_EXTRA_PARAMS=&#39;--plugin=/home/simnet/.lightning/plugins/jitrebalance.py&#39;

add lightningd alice
cp -r &quot;$SIMVERSE_REPOS/plugins/jitrebalance&quot; &quot;$SIMVERSE_WORKSPACE/$SIMNET_NAME/_volumes/lightning-data-alice/plugins&quot;

add lightningd bob
cp -r &quot;$SIMVERSE_REPOS/plugins/jitrebalance&quot; &quot;$SIMVERSE_WORKSPACE/$SIMNET_NAME/_volumes/lightning-data-bob/plugins&quot;

add lightningd charlie
cp -r &quot;$SIMVERSE_REPOS/plugins/jitrebalance&quot; &quot;$SIMVERSE_WORKSPACE/$SIMNET_NAME/_volumes/lightning-data-charlie/plugins&quot;


# generate init script to build connections
cat &gt; init &lt;&lt;EOF
#!/usr/bin/env bash

set -e -o pipefail

# connect LN nodes
connect alice charlie
connect charlie bob
connect bob alice
EOF
chmod +x init</code></pre><p>What is happening here? First we import the <code>cookbook</code> library. <code>prelude</code> does all the preliminary stuff needed for every cluster. After this we can start adding our back-end and our Lighning nodes. <code>add bitcoind</code> adds the bitoind node (duh!). Before we add our c-lightning nodes we set the <code>LIGHTNINGD_EXTRA_PARAMS</code> variable. This variable is passed to <code>lightningd</code> when starting up the Docker container. We use it to set the <code>plugin</code> argument.</p><p>We can now add our first lightning node, called &quot;alice&quot;: <code>add lightningd alice</code> After this we can copy our plugin to the Docker context folder with the following command:</p><pre><code class=language-bash>cp -r &quot;$SIMVERSE_REPOS/plugins/jitrebalance&quot; &quot;$SIMVERSE_WORKSPACE/$SIMNET_NAME/_volumes/lightning-data-alice/plugins&quot;</code></pre><p>We use several variables that may require some explanation. <code>$SIMVERSE_REPOS</code> holds the folder containing the Simverse repos. Since we have cloned our plugins repo into that folder, we can find it there. <code>$SIMVERSE_WORKSPACE</code> holds the folder where Simverse stores all the files required for creating a cluster. <code>$SIMNET_NAME</code> holds the name of the cluster. When we create a cluster based on this recipe, we also have to give that cluster a name. That name is available through the <code>$SIMNET_NAME</code> variable. The rest of theDocker context folder follows a simple naming convention: <code>_volumes/[node type]-[node name]</code></p><p>We do the same thing for Bob and Charlie.</p><p>The last part of our recipe can be left out if you want. It generates an initialization script that can be run after creating the cluster. In this case it connects the nodes, but you can also use it to fund nodes and make transactions, build multiple scripts and what not. It just shows how versatile Simverse is.</p><p>We can save our recipe. There are some simple naming conventions that you can follow that make easy to see what kind of back-end(s) and nodes this cluster uses:</p><ul><li><code>a</code>: bitcoind</li><li><code>b</code>: btcd</li><li><code>k</code>: lightningd</li><li><code>l</code>: lnd</li><li><code>m</code>: eclair</li></ul><p>So <code>a1k3</code> reads as &quot;one bitcoind node and two c-lightning nodes&quot;. You should use a postfix to identify any additional distinguishing features of the recipe. So in this case we save our recipe as <code>a1k3-plugin.sh</code> in the recipe folder of Simverse located at <code>~/simverse/recipes</code>.</p><h2 id=building-your-cluster>Building your cluster</h2><p>With our recipe out of the way we can create our cluster.</p><pre><code class=language-bash>cd ~/simverse
./sv create a1k3-plugin jitrebalance
./sv enter jitrebalance
./dc build
./dc up</code></pre><p>We have created a cluster named <code>jitrebalance</code>. This is the name of the cluster that we referenced in our recipe through the variable <code>$SIMNET_NAME</code>. Our cluster is based on the recipe <code>a1k3-plugin.sh</code> that we just created. With <code>enter</code> you enter your newly created simnet.</p><p><code>./dc</code> is a handy shorthand for <code>docker-compose</code> with some important variables set. With <code>build</code> we build our Docker containers based on the <code>docker-compose.yml</code> that has been generated for us. And then we are ready to run the containers with <code>up</code>.</p><p>You should see something like this:</p><p><picture><source srcset="/images/simverse-up_s.avif 540w,/images/simverse-up_m.avif 810w,/images/simverse-up_l.avif 1080w" type=image/avif><source srcset="/images/simverse-up_s.webp 540w,/images/simverse-up_m.webp 810w,/images/simverse-up_l.webp 1080w" type=image/webp><img srcset="/images/simverse-up_s.jpg 540w,/images/simverse-up_m.jpg 810w,/images/simverse-up_l.jpg 1080w" src=/images/simverse-up_s.jpg alt="running Simverse" title="Running a Simverse cluster" loading=lazy decoding=async width=1080 height=610><figcaption>Running a Simverse cluster</figcaption></picture></p><p>Now in a separate terminal session you can access your nodes and run the <code>init</code> script.</p><pre><code class=language-bash>cd ~/simverse
./sv enter jitrebalance
./init</code></pre><p><picture><source srcset="/images/simverse-init_s.avif 540w,/images/simverse-init_m.avif 810w,/images/simverse-init_l.avif 1080w" type=image/avif><source srcset="/images/simverse-init_s.webp 540w,/images/simverse-init_m.webp 810w,/images/simverse-init_l.webp 1080w" type=image/webp><img srcset="/images/simverse-init_s.jpg 540w,/images/simverse-init_m.jpg 810w,/images/simverse-init_l.jpg 1080w" src=/images/simverse-init_s.jpg alt="running init" title="Running the initialization script" loading=lazy decoding=async width=1080 height=410><figcaption>Running the initialization script</figcaption></picture></p><p>And with that you are done! You have now a Simverse cluster with three c-lightning nodes running the same plugin.</p></div></div></div><div class=metadata><a href=/post/running-c-lightning-in-simverse-with-plugins class=u-url><time class=dt-published datetime=2020-12-02T00:00:00Z>2020-12-02 00:00:00 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><h1 class=p-name>SSH keybased authentication Windows to Linux</h1><div class=e-content><p>I do most of my development on a remote machine. The machine isn&#39;t <em>that</em> remote, it&#39;s a mini-pc running Ubuntu that is standing right here on my desk. It has no peripherals, so I have to do all my development remotely through my Windows 10 laptop.</p><p>Remote development with Vscode is amazing. It just works. Once you are set up, there&#39;s no difference with working locally. To have that seamless experience you do have to set up keybased authentication for SSH. If you don&#39;t you will be constantly reminded of working remotely, because you have to type in the password of the remote machine.</p><p>Configuring keybased authentication is <a href=https://code.visualstudio.com/docs/remote/troubleshooting#_configuring-key-based-authentication>documented</a>, but yesterday I had to go through it again, and it confused me...again. So this is my go at explaining it less confusing for the specific case of working on a <em>local Windows machine</em> and connecting to a <em>remote Linux machine</em>. So open up that PowerShell and let&#39;s start.</p><p>Install the OpenSSH client if you haven&#39;t already. It is a optional feature of Windows 10. Search for &#39;Manage Optional Features&#39; in the Windows Start Menu and click on it. Scan the list to see if OpenSSH client is already installed. If not, then do so by clicking on &quot;Add a feature&quot;.</p><p>If you haven&#39;t got a local SSH key pair, you should create one.</p><pre><code class=language-PowerShell>ssh-keygen -t rsa -b 4096</code></pre><p>You can accept all defaults and keep the passphrase empty. It will result in a keypair generated in the <code>$HOME\.ssh\</code> folder which we will use later.</p><p><picture><source srcset="/images/ssh-keypair_s.avif 474w,/images/ssh-keypair_m.avif 711w,/images/ssh-keypair_l.avif 948w" type=image/avif><source srcset="/images/ssh-keypair_s.webp 474w,/images/ssh-keypair_m.webp 711w,/images/ssh-keypair_l.webp 948w" type=image/webp><img srcset="/images/ssh-keypair_s.jpg 474w,/images/ssh-keypair_m.jpg 711w,/images/ssh-keypair_l.jpg 948w" src=/images/ssh-keypair_s.jpg alt="Create your local SSH key pair" title="Create your local SSH key pair" loading=lazy decoding=async width=948 height=622><figcaption>Create your local SSH key pair</figcaption></picture></p><p>You are now ready to add your <em>local</em> key to the autorized keys on your <em>remote</em> machine. Run the following in PowerShell on your <em>local</em> machine.</p><pre><code class=language-PowerShell>$USER_AT_HOST=&quot;your-user-name-on-host@hostname&quot;
$PUBKEYPATH=&quot;$HOME\.ssh\id_rsa.pub&quot;

$pubKey=(Get-Content &quot;$PUBKEYPATH&quot; | Out-String); ssh &quot;$USER_AT_HOST&quot; &quot;mkdir -p ~/.ssh &amp;&amp; chmod 700 ~/.ssh &amp;&amp; echo &#39;${pubKey}&#39; &gt;&gt; ~/.ssh/authorized_keys &amp;&amp; chmod 600 ~/.ssh/authorized_keys&quot;</code></pre><p>And that&#39;s it. You can now SSH into your remote machine without needing a password.</p></div></div></div><div class=metadata><a href=/post/ssh-keybased-authentication-windows-to-linux class=u-url><time class=dt-published datetime=2020-11-20T00:00:00Z>2020-11-20 00:00:00 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><h1 class=p-name>Debugging LND while running a local cluster</h1><div class=e-content><p>If you want to debug LND, or if you want to take a real deep dive into LND, you probably want to be able to set breakpoints in the source code to see what is actually happening. Not only that, you also want to have the node run in a local cluster of other nodes, so that you can perform some real Lightning actions like opening a channel and make payments. This post takes you through the setup I use based on <a href=https://github.com/go-delve/delve>Delve</a> and <a href=https://github.com/darwin/simverse>Simverse</a>.</p><h2 id=setting-up-a-local-cluster-with-simverse>Setting up a local cluster with Simverse</h2><p>Simverse is an amazing tool for setting up local Lightning clusters. It uses docker-compose to manage the cluster and supports LND, c-lightning and Eclair nodes with either btcd or bitcoind back-ends. This makes it very easy to set up local clusters of any size, as long as your hardware can handle it. All nodes and back-ends are run in their own docker containers and are spun up on demand following a default recipe or a custom recipe that you can draft up yourself. It literally takes four commands to have a local cluster running with Simverse.</p><p>For our setup we will use a hybrid cluster. There are 3 types of Simverse clusters: Homogenous clusters are Simverse clusters that run either lnd + btcd nodes, eclair + bitcoind nodes or c-lightning + bitcoind nodes. More generally speaking, a homgenous cluster only contains one flavor of back-end and one flavor of Lightning node. The second type of cluster is heterogenous cluster, containing a mix of nodes and back-ends. The third type of cluster is called a hybrid cluster. This is a Simverse cluster (either homogenous or heterogenous) that interacts with an external node that runs directly on the host machine instead of in a docker container. We will use the default Simverse cluster (a homogenous lnd + btcd cluster) and make it hybrid by connecting the LND node that runs the code that we are going to debug.</p><p>Setting up the cluster with Simverse is not within the scope of this article, but the <a href=https://github.com/darwin/simverse>Quickstart</a> of Simverse is all you need to do. That will result in having a cluster with 3 Docker containers, two running LND, and one running a btcd back-end.</p><h2 id=building-lnd>Building LND</h2><p>We need to build de debug version of LND, to be able to do some debugging. I will be using the repo that Simverse automatically cloned. Simverse clones repos into the <code>_repos</code> folder inside the Simverse folder. In my case the Simverse folder is located here: <code>~/simverse/_repos</code>.</p><pre><code>cd ~/simverse/_repos/lnd
make build</code></pre><p>The resulting binaries can be found in the repo folder itself: <code>lnd-debug</code> and <code>lncli-debug</code></p><h2 id=create-a-lndconf-file>Create a lnd.conf file</h2><p>Yes, you can start lnd with a bunch of arguments. So there is no real need for a conf-file, but I think it makes it way easier to start LND with a conf-file. You can place your file anywhere, but I find it easy to have them all at a single place, and the most logical place is the default location: <code>~/.lnd/</code>.</p><p>Give it a name that makes it easy to understand that this is a conf file not be used in a production environment, like <code>lnd-test.conf</code>.</p><p>These are the contents of my <code>lnd-test.conf</code>:</p><pre><code>noseedbackup=true
bitcoin.active=true
bitcoin.regtest=true
no-macaroons=true
bitcoin.node=btcd
btcd.rpchost=default_btcd1
btcd.rpccert=/home/mini/simverse/_workspace/default/_volumes/certs/rpc.cert
btcd.rpcuser=devuser
btcd.rpcpass=devpass
debuglevel=debug</code></pre><p>What this configuration does is running LND with (completely unsafe) development settings, using the btcd Docker container as the back-end.</p><p>You would have to change <code>btcd.rpcert</code> to the path to the <code>rpc.cert</code> file in your Simverse workspace and you would probably have to change the <code>btcd.rpchost</code> as well. The <code>default_btcd1</code> host pointing to your btcd Docker container is <em>not</em> automatically added to your host file so either you have to add it to your host file or you have to replace it with an IP address. You can find the IP address of the btcd1 docker container of your Simverse cluster, by using the <code>list_docker_ips</code> command that ships with Simverse. (I told you that tool was amazing). An alternative solution is to run this <a href=https://github.com/dvddarias/docker-hoster>extra docker container</a> that automatically updates entries in your hostfile.</p><h2 id=installing-delve>Installing Delve</h2><p>Assuming you have Vscode installed, make sure you have installed the <a href="https://marketplace.visualstudio.com/items?itemName=golang.Go">language support for Go</a> extension.</p><p>Open the Command Palette, select <code>Go: Install/Update Tools</code>, and select <code>dlv</code></p><p><picture><source srcset="/images/install-dlv_s.avif 540w,/images/install-dlv_m.avif 810w,/images/install-dlv_l.avif 1080w" type=image/avif><source srcset="/images/install-dlv_s.webp 540w,/images/install-dlv_m.webp 810w,/images/install-dlv_l.webp 1080w" type=image/webp><img srcset="/images/install-dlv_s.jpg 540w,/images/install-dlv_m.jpg 810w,/images/install-dlv_l.jpg 1080w" src=/images/install-dlv_s.jpg alt="install dlv" title="Install dlv using the Command Palette" loading=lazy decoding=async width=1080 height=142><figcaption>Install dlv using the Command Palette</figcaption></picture></p><h2 id=configure-launchjson>Configure launch.json</h2><p>Open the folder of your LND repo with Vscode and create a launch.json file by selecting the gear icon on the Run view (<kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>D</kbd>) top bar.</p><pre><code class=language-lang-json>{
    &quot;version&quot;: &quot;0.2.0&quot;,
    &quot;configurations&quot;: [
        {
            &quot;name&quot;: &quot;Launch lnd&quot;,
            &quot;type&quot;: &quot;go&quot;,
            &quot;request&quot;: &quot;launch&quot;,
            &quot;mode&quot;: &quot;exec&quot;,
            &quot;program&quot;: &quot;${workspaceFolder}/lnd-debug&quot;,
            &quot;env&quot;: {},
            &quot;args&quot;: [&quot;--configfile=~/.lnd/lnd-test.conf&quot;],
            &quot;showLog&quot;: true
        }
    ]
}</code></pre><p>The args parameter should contain the location of your conf-file.</p><h2 id=set-breakpoints>Set breakpoints</h2><p>Now you are ready to set breakpoints, for instance in the <code>Main</code> function of the <code>lnd</code> package.</p><p><picture><source srcset="/images/set-breakpoint_s.avif 540w,/images/set-breakpoint_m.avif 810w,/images/set-breakpoint_l.avif 1080w" type=image/avif><source srcset="/images/set-breakpoint_s.webp 540w,/images/set-breakpoint_m.webp 810w,/images/set-breakpoint_l.webp 1080w" type=image/webp><img srcset="/images/set-breakpoint_s.jpg 540w,/images/set-breakpoint_m.jpg 810w,/images/set-breakpoint_l.jpg 1080w" src=/images/set-breakpoint_s.jpg alt="Main function" title="Main function" loading=lazy decoding=async width=1080 height=488><figcaption>Main function</figcaption></picture></p><p>If you start debugging, this breakpoint is immediately hit.</p><p><picture><source srcset="/images/hit-breakpoint_s.avif 540w,/images/hit-breakpoint_m.avif 810w,/images/hit-breakpoint_l.avif 1080w" type=image/avif><source srcset="/images/hit-breakpoint_s.webp 540w,/images/hit-breakpoint_m.webp 810w,/images/hit-breakpoint_l.webp 1080w" type=image/webp><img srcset="/images/hit-breakpoint_s.jpg 540w,/images/hit-breakpoint_m.jpg 810w,/images/hit-breakpoint_l.jpg 1080w" src=/images/hit-breakpoint_s.jpg alt="Breakpoint hit" title="Breakpoint hit" loading=lazy decoding=async width=1080 height=255><figcaption>Breakpoint hit</figcaption></picture></p><h2 id=done>Done!</h2><p>And there you have it, you can now start to debugging LND operating in a local cluster.</p></div></div></div><div class=metadata><a href=/post/debugging-lnd-while-running-a-local-cluster class=u-url><time class=dt-published datetime=2020-11-16T00:00:00Z>2020-11-16 00:00:00 +00:00</time></a></div></div></li><li><div class=h-entry><div class=tweet-container><div class="u-author h-card"><a href=/ class=u-url><img src=/images/gijsvandam.jpg alt="Gijs van Dam" class="u-photo p-name"></a></div><div class=tweet><h1 class=p-name>Building Bitcoin Core On Windows 10</h1><div class=e-content><p>I&#39;ve been following Bitcoin and more importantly the Blockchain from the sidelines for a few years now, but I wanted to get my hands dirty. Obviously I could just download the Bitcoin Core executables from bitcoin.org, but I always feel it gives me more insight if I build something myself. Also it&#39;s was a nice test case for Bash on Windows.</p><p>If you haven&#39;t done so already, you need to activate this feature for Windows. It&#39;s only available on 64-bit Windows 10. You can follow the instructions for this on <a href=https://github.com/bitcoin/bitcoin/blob/master/doc/build-windows.md>https://github.com/bitcoin/bitcoin/blob/master/doc/build-windows.md</a> There&#39;s a catch, however. At the time of writing the Windows 10 bash feature comes with Ubuntu Xenial 16.04, which is exactly the Ubuntu version on which the build of Bitcoin Core is broken. So first check what version you are on.</p><pre><code>lsb_release -a</code></pre><p>Your version appears on the &quot;Description&quot; line. If it is 16.04, which is the current latest LTS-version (Long Term Support) of Ubuntu, you&#39;ll have to upgrade to the next version. For this to work you&#39;ll need to change the file with the release-upgrade settings using vi.</p><pre><code>sudo vi /etc/update-manager/release-upgrades
# Find the line that reads:
Prompt=LTS
# Change it to:
Prompt=normal</code></pre><p>Run</p><pre><code>sudo do-release-upgrade</code></pre><p>After I was done, <code>lsb_release -a</code> yielded the brand new Ubuntu Zesty 17.04 in the description. On with the instructions on <a href=https://github.com/bitcoin/bitcoin/blob/master/doc/build-windows.md>https://github.com/bitcoin/bitcoin/blob/master/doc/build-windows.md</a>. Take note that you have to install the dependencies for g++-mingw-w64-x86-64 and mingw-w64-x86-64-dev first, before changing the update-alternatives. The instructions are a bit confusing on this point.</p><pre><code>sudo apt-get install git
cd /usr/local/src
sudo git clone https://github.com/bitcoin/bitcoin.git
PATH=$(echo &quot;$PATH&quot; | sed -e &#39;s/:\/mnt.*//g&#39;)
cd bitcoin/depends
sudo make HOST=x86_64-w64-mingw32
cd ..
sudo ./autogen.sh
sudo CONFIG_SITE=$PWD/depends/x86_64-w64-mingw32/share/config.site ./configure --prefix=/
sudo make</code></pre><p>The first build took roughly 2 hours, so sit back and keep an eye on it from time to time.</p><p>Apparently it is useful to copy the compiled executables to a directory on the windows drive in the same directory structure as they appear in the release .zip archive. This can be done in the following way (I already created a folder on the windows drive: c:\workspace\bitcoin although I&#39;m not sure if that&#39;s needed):</p><pre><code>sudo make install DESTDIR=/mnt/c/workspace/bitcoin</code></pre><p>Again, sit back and wait for the process to finish.</p><p>After the process has finished successfully, you will find the executables here: C:\workspace\bitcoin\bin Starting bitcoin-qt.exe will start Bitcoin Core, the GUI node for Bitcoin.</p></div></div></div><div class=metadata><a href=/post/building-bitcoin-core-on-windows-10 class=u-url><time class=dt-published datetime=2017-11-03T00:00:00Z>2017-11-03 00:00:00 +00:00</time></a></div></div></li><li class=article-pagination><a href=/feed/3 class=article-pagination-right>Newer posts</a></li></ul></main><footer><nav><ul><li><a href=/ title=Home>Home</a></li><li><a href=/research title=Research>Research</a></li><li><a href=/open-source title="Open Source">Open Source</a></li><li><a href=/ventures title=Ventures>Ventures</a></li><li><a href=/resume title=Resume>Resume</a></li><li><a href=/about title=About>About</a></li><li><a href=/now title=Now>Now</a></li><li><a href=/contact title=Contact>Contact</a></li></ul></nav><ul><li><div itemscope itemtype=https://schema.org/Person><a itemprop=sameAs content=https://www.github.com/gijswijs href=https://www.github.com/gijswijs rel="noreferrer noopener me" target=_blank title=Github>Github</a></div></li><li><div itemscope itemtype=https://schema.org/Person><a itemprop=sameAs content=https://www.linkedin.com/in/gijsvandam/ href=https://www.linkedin.com/in/gijsvandam/ rel="noreferrer noopener me" target=_blank title=LinkedIn>LinkedIn</a></div></li><li><div itemscope itemtype=https://schema.org/Person><a itemprop=sameAs content=https://www.researchgate.net/profile/Gijs_Van_Dam2 href=https://www.researchgate.net/profile/Gijs_Van_Dam2 rel="noreferrer noopener me" target=_blank title=ResearchGate>ResearchGate</a></div></li><li><div itemscope itemtype=https://schema.org/Person><a itemprop=sameAs content=https://bitcoinhackers.org/@gijswijs href=https://bitcoinhackers.org/@gijswijs rel="noreferrer noopener me" target=_blank title=Mastodon>Mastodon</a></div></li><li><div itemscope itemtype=https://schema.org/Person><a itemprop=sameAs content=https://www.twitter.com/gijswijs href=https://www.twitter.com/gijswijs rel="noreferrer noopener me" target=_blank title=Twitter>Twitter</a></div></li><li><a href=/feed rel=feed target=_self title=Stream>Stream</a></li><li><a href=/rss.xml rel="" target=_blank title=RSS>RSS</a></li><li><div itemscope itemtype=https://schema.org/Person><a itemprop=sameAs content=https://keybase.io/gijsvandam href=https://keybase.io/gijsvandam rel="noreferrer noopener me" target=_blank title=Keybase>Keybase</a></div></li><li><div itemscope itemtype=https://schema.org/Person><a itemprop=sameAs content=https://orcid.org/0000-0002-6188-6859 href=https://orcid.org/0000-0002-6188-6859 rel="noreferrer noopener me" target=_blank title=ORCID>ORCID</a></div></li><li><div itemscope itemtype=https://schema.org/Person><a itemprop=sameAs content="https://scholar.google.com/citations?user=4dTcK4kAAAAJ&amp;hl=en" href="https://scholar.google.com/citations?user=4dTcK4kAAAAJ&amp;hl=en" rel="noreferrer noopener me" target=_blank title="Google Scholar">Google Scholar</a></div></li></ul><p>&copy; 2022 <a href=/ >Gijs van Dam</a>. Published with <a href=https://github.com/neumannjs/Janos>Janos</a>. Theme <a href=https://github.com/neumannjs/Miksa>Miksa</a>.</p></footer></body><script data-goatcounter=https://gijsvandam.goatcounter.com/count async src=//gc.zgo.at/count.js></script></html>